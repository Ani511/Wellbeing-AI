# ğŸ’š Wellbeing AI â€” Predictive Health Risk Scoring with Explainable ML & Empathetic Recommendations

> ğŸ§  Using CDCâ€™s BRFSS Dataset Â· XGBoost Â· LIME/ELI5 Â· Streamlit Â· Power BI  
> ğŸ“… Project Date: May 2025 &nbsp;&nbsp;&nbsp;&nbsp;ğŸ”— [Kaggle Dataset](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system)

---
## ğŸ©º Problem Statement

Preventive healthcare in underserved and vulnerable populations is often hindered by the lack of explainable risk assessments based on **Social Determinants of Health (SDOH)**. Traditional models ignore non-clinical data such as mental health, socioeconomic status, lifestyle, or access to care.

This project aims to build an AI-powered tool that uses publicly available health survey data to:

- Predict an individual's risk of developing **chronic conditions**
- Provide **interpretable insights** behind the prediction
- Suggest **empathetic, actionable health guidance**
- Support **population-level policy decisions** through BI dashboards

---
## ##ğŸ”¬ Research Intention

Most predictive health models prioritize raw accuracy over probabilistic reliability. In high-stakes settings like preventive healthcare, an uncalibrated model can provide "confidently wrong" predictions. This project focuses on bridging the gap between high-performance gradient boosting and interpretable, well-calibrated risk estimation.

---

## ğŸš€ Key Research Contributions

### 1. Model Calibration & Uncertainty Estimation
Standard XGBoost models often output distorted probabilities (sigmoidal curves). I implemented a **calibration layer** to ensure that predicted risk scores map accurately to real-world frequencies.
* **Method:** Utilized `CalibratedClassifierCV` (Sigmoid/Platt Scaling and Isotonic Regression).
* **Metrics:** Evaluated model performance using **Brier Score** and **Log-Loss** to assess the quality of predicted probabilities beyond simple Accuracy/F1.
* **Validation:** Generated **Reliability Diagrams** to visualize the alignment between predicted probability and empirical frequency.



### 2. Explainable AI (XAI) for Safety-Critical Systems
To ensure model decisions are grounded in Social Determinants of Health (SDOH) rather than noise, I integrated post-hoc interpretability tools:
* **Local Explanations:** Used **LIME** to generate per-individual risk breakdowns, essential for clinician-patient trust.
* **Global Insights:** Used **ELI5 (Permutation Importance)** to verify that the modelâ€™s "logic" aligns with established medical literature (e.g., the high impact of BMI and physical activity on chronic disease).



### 3. Handling Extreme Class Imbalance & SDOH
The CDC BRFSS dataset is highly skewed. I addressed this using a combination of **Stratified Sampling** and **Scale_Pos_Weight** in XGBoost to ensure the model maintains sensitivity for minority "At Risk" classes while maintaining calibration.

---
## ğŸ“š Dataset

- ğŸ“¦ **Source**: [CDC Behavioral Risk Factor Surveillance System (BRFSS)](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system)
- ğŸ§® **Size**: 400,000+ anonymized survey records (2020â€“2022)
- ğŸ§  **Features**: 300+ variables on physical & mental health, lifestyle, access to care, geography, and demographics

---

## ğŸ§¾ Project Summary

We built an end-to-end ML system using BRFSS data to predict chronic disease risk and explain predictions using human-readable methods.

### ğŸ¯ Goals:
- Clean, structure, and model the BRFSS dataset
- Predict whether a person is at risk for chronic conditions like diabetes, heart disease, etc.
- Use **explainable AI** to break down *why* that risk exists
- Generate **natural language health recommendations**
- Visualize high-risk groups using **clustering** and **Power BI**

---

## âœ… Results

- Achieved **balanced accuracy >80%** on chronic disease prediction using calibrated XGBoost
- Successfully identified and visualized **key social determinants** contributing to risk (e.g., exercise, depression, income, healthcare access)
- Delivered **interpretable explanations per individual** using LIME & ELI5
- Built a working prototype of a **Streamlit app** for personal health feedback
- Designed **Power BI dashboards** to visualize risk across different regions and demographics
- * **Calibration Impact:** Post-hoc calibration significantly improved the **Brier Score**, enhancing the reliability of the 0-1 risk scale for clinical decision support.
* **SDOH Clustering:** Power BI analysis revealed that lower-income brackets correlated strongly with high "model-predicted risk," validating the model's ability to pick up on socioeconomic stressors.
* **Explainability:** LIME confirmed that "Mental Health" and "Access to Care" were top risk drivers for certain demographics, highlighting key areas for preventive intervention.

---

## ğŸ”‘ Key Features

- ğŸ” **Risk Prediction**: Binary classification for chronic disease presence using XGBoost
- âš–ï¸ **Class Imbalance Handling**: Resampling and calibration to account for underrepresented outcomes
- ğŸ’¬ **Explainability Layer**: LIME & ELI5 breakdown of prediction factors
- ğŸ¤– **LLM Recommender**: Natural language health tips based on risk and feature influence
- ğŸ“Š **Power BI Dashboards**: Public health-level visual insights on SDOH clustering
- ğŸ§ª **Fully Modular**: Clean separation of EDA, modeling, explainability, and dashboarding notebooks

---

## ğŸ’¡ Example Use Cases

- ğŸ‘¨â€âš•ï¸ A family doctor gives a patient a risk score with clear reasoning: â€œYou may be at higher risk for diabetes because of recent inactivity, BMI, and mental health scores.â€
- ğŸ¥ A public health department clusters at-risk individuals by state and income level to optimize outreach
- ğŸ§  A health policy researcher investigates which lifestyle factors most influence risk for women under 40

---

## ğŸ› ï¸ Technical Stack & Methodology

| Component | Tool | **Research Application** |
| :--- | :--- | :--- |
| **Modeling** | XGBoost, Scikit-learn | Calibrated Gradient Boosting for non-linear risk estimation. |
| **Calibration** | `CalibratedClassifierCV` | Implementation of Isotonic & Sigmoid scaling for probability refinement. |
| **Interpretability** | LIME, ELI5 | Feature attribution and local surrogate modeling. |
| **Data Engine** | Python, Polars | Handling 400k+ records with efficient, vectorized pre-processing. |
| **Deployment** | Streamlit, Power BI | Translating mathematical scores into empathetic user-facing interfaces. |

---

## ğŸ—‚ï¸ Project Structure

- `EDA_Preprocessing.ipynb` â€” Data cleaning, feature selection, correlation maps
- `Modelling_Healthscore.ipynb` â€” XGBoost training, calibration, evaluation
- `mExplainability.ipynb` â€” ELI5 + LIME interpretability for predictions
- `LLM_Recommeder.ipynb` â€” Personalized, empathetic text suggestions
- `outputs ` - Contains final model outputs including ELI5 and LIME explanations, top feature summaries, a batch of personalized health recommendations, and the calibrated XGBoost pipeline.  
  *(Note: The final `risk_scores_with_recc.csv` file is not uploaded due to size limits.)*
- `README.md` â€” Project overview (this file)

---

## âš ï¸ Note on Dataset

Due to GitHubâ€™s file size constraints, the original dataset is not included.

You can download it from Kaggle:  
ğŸ”— [CDC BRFSS Dataset](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system)

---

## ğŸ§¾ Input & Output

### ğŸ”¹ Input:
- Raw `.csv` files from CDC BRFSS survey (2020â€“2022)
- Features include: age, gender, BMI, physical activity, depression, access to healthcare, etc.

### ğŸ”¹ Output:
- Binary prediction: `"At Risk"` / `"Not At Risk"` for chronic conditions
- Explainable feature contributions (e.g., `"Low physical activity: +0.12 risk"`)
- Natural-language recommendation (LLM output):  
  > â€œTo reduce your risk, consider increasing physical activity and regular check-upsâ€¦â€

---

## ğŸ› ï¸ How to Run Locally

1. **Clone the repo:**
   ```bash
   git clone https://github.com/Ani511/Wellbeing-AI.git
   cd Wellbeing-AI

2. Install dependencies:
    pip install -r requirements.txt
    Download & add BRFSS CSVs into a data/ folder

3. Open & run notebooks:
- jupyter notebook modeling/Modelling_Healthscore.ipynb
- run app.py
- streamlit run app.py

---
### ğŸ“Š Power BI Dashboards
To complement the ML pipeline, we designed Power BI dashboards using cleaned BRFSS data to help visualize:

- ğŸ“ SDOH patterns across states and age groups
- ğŸ’¡ Distribution of key risk factors (e.g., physical inactivity, depression, obesity)
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Clustering of at-risk populations by income, access to care, and lifestyle
- ğŸ¥ Potential intervention zones for preventive healthcare outreach

These dashboards support public health researchers and policymakers in identifying vulnerable groups and targeting data-driven wellness campaigns.

âš ï¸ Due to size limits and platform restrictions, .pbix files are not included in the repository but are available upon request.

--- 
### ğŸ§  Highlights & Conclusion
âœ… Human-centered risk scoring from publicly available data
âœ… Modular notebook structure and clear code flow
âœ… Strong emphasis on interpretability and health empathy
âœ… Scalable for use in mobile health apps or public policy systems

This project demonstrates how responsible ML can support both individual well-being and large-scale health strategy.
